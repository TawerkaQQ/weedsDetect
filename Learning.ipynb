{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd1e73a-0e0b-4633-ad82-160c4b9ab24b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 13:45:54.253535: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 13:45:56.630020: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-07 13:45:56.630139: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-09-07 13:45:56.630151: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.io import decode_jpeg,read_file\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.layers import Conv2D,Dropout,MaxPool2D,Dense,Flatten,Rescaling,RandomFlip,RandomRotation,Resizing, BatchNormalization, AveragePooling1D\n",
    "from keras import metrics\n",
    "from tensorflow.keras.metrics import Metric\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58119a21-e7d8-4b29-ab62-f6739eefb195",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd2854e-477f-4f43-b9fa-8875644c5a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path_data = \"./ambrosia+/train/1800006/*.jpg\"\n",
    "# files = glob.glob(path_data,recursive=True)\n",
    "# files = files[230:]\n",
    "# print(len(files))\n",
    "# for i in files:\n",
    "#     os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "732a2863-3fe3-4b3a-b238-ff7a44e133de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8047 files belonging to 2 classes.\n",
      "Found 42 files belonging to 2 classes.\n",
      "Found 935 files belonging to 2 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 14:10:21.090078: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [8047]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-07-04 14:10:21.090444: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [8047]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 16s 126ms/step - loss: 81.6781 - accuracy: 0.5576\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 15s 130ms/step - loss: 5.7804 - accuracy: 0.5652\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 15s 129ms/step - loss: 1.7175 - accuracy: 0.6286\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 15s 129ms/step - loss: 1.5856 - accuracy: 0.7603\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 15s 129ms/step - loss: 1.5197 - accuracy: 0.7993\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 15s 130ms/step - loss: 1.5040 - accuracy: 0.8048\n",
      "Epoch 7/10\n",
      "112/112 [==============================] - 15s 129ms/step - loss: 1.4930 - accuracy: 0.8173\n",
      "Epoch 8/10\n",
      "112/112 [==============================] - 15s 130ms/step - loss: 1.4772 - accuracy: 0.8184\n",
      "Epoch 9/10\n",
      "112/112 [==============================] - 15s 129ms/step - loss: 1.5556 - accuracy: 0.8232\n",
      "Epoch 10/10\n",
      "112/112 [==============================] - 15s 130ms/step - loss: 1.5226 - accuracy: 0.8227\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 14:12:56.287073: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [935]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-07-04 14:12:56.287609: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [935]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 2s 44ms/step - loss: 1.4262 - accuracy: 0.8738\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 14:12:57.846684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [42]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-07-04 14:12:57.847117: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [42]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 552ms/step - loss: 1.8536 - accuracy: 0.6905\n"
     ]
    }
   ],
   "source": [
    "path_data = \"./ambrosia+/train/\"\n",
    "BATCH_SIZE = 72\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    path_data,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(225,225)\n",
    ")\n",
    "IRL_path = \"./ambrosia+/testIRL/\"\n",
    "dataset_IRL = tf.keras.utils.image_dataset_from_directory(\n",
    "    IRL_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(225,225)\n",
    ")\n",
    "test_path = \"./ambrosia+/test/\"\n",
    "dataset_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(225,225))\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(16,3,input_shape=(225,225,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(16,3,activation=\"relu\",padding=\"same\"))\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(16,3,activation=\"relu\",padding=\"same\"))\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.L1L2(l1=0.07, l2=0.05)))\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=0.0017,momentum=0.004),loss=keras.losses.BinaryCrossentropy(),metrics=[\"accuracy\"])\n",
    "model.fit(dataset,epochs=10)\n",
    "print(\"\")\n",
    "model.evaluate(dataset_test)\n",
    "print(\"\")\n",
    "model.evaluate(dataset_IRL)\n",
    "model.save_weights(\"ambrosia_next_sgd_nesterov_drop40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef6095-ab7e-4143-bb86-e7c833aad4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33984 files belonging to 2 classes.\n",
      "Using 10195 files for validation.\n",
      "Found 1274 files belonging to 2 classes.\n",
      "Found 104 files belonging to 2 classes.\n",
      "Epoch 1/40\n",
      "102/102 [==============================] - 168s 1s/step - loss: 282.0865 - accuracy: 0.5923\n",
      "Epoch 2/40\n",
      "102/102 [==============================] - 213s 2s/step - loss: 279.7760 - accuracy: 0.7183\n",
      "Epoch 3/40\n",
      "102/102 [==============================] - 171s 2s/step - loss: 277.4941 - accuracy: 0.7653\n",
      "Epoch 4/40\n",
      "  6/102 [>.............................] - ETA: 2:28 - loss: 276.2926 - accuracy: 0.7850"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "dataset_train_path = \"./dataset_ambrosia/train\"\n",
    "dataset_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    validation_split=0.3,\n",
    "    subset='validation',\n",
    "    image_size=(224,224))\n",
    "\n",
    "dataset_val_path = \"./dataset_ambrosia/val\"\n",
    "dataset_val = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_val_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(224,224))\n",
    "\n",
    "\n",
    "test1_path = \"./dataset_ambrosia/test\"\n",
    "dataset_test = tf.keras.utils.image_dataset_from_directory(\n",
    "    test1_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(224,224))\n",
    "\n",
    "# test2_path = \"./dataset_ambrosia/test_2\"\n",
    "# dataset_test2 = tf.keras.utils.image_dataset_from_directory(\n",
    "#     test2_path,\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"int\",\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     image_size=(350,350))\n",
    "\n",
    "# test2_crop_path = \"./dataset_ambrosia/test_2_crop\"\n",
    "# dataset_test2_crop = tf.keras.utils.image_dataset_from_directory(\n",
    "#     test2_crop_path,\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"int\",\n",
    "#     color_mode=\"rgb\",\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     image_size=(350,350))\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(64,2,input_shape=(224,224,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(64,3,activation=\"relu\",padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(128,3,activation=\"relu\",padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(128,3,activation=\"relu\",padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(256,3,activation=\"relu\",padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(256,3,activation=\"relu\",padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(512,3,activation=\"relu\",padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(512,3,activation=\"relu\",padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(1024,3,activation=\"relu\",padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))# test\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\"))\n",
    "model.add(Conv2D(1024,3,activation=\"relu\",padding=\"same\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(MaxPool2D(2,padding=\"same\")) # end test\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "# model.add(Dropout(0.45))\n",
    "model.add(Dense(2048,activation=\"relu\", kernel_regularizer=tf.keras.regularizers.L2(l2=0.05)))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer=keras.optimizers.experimental.RMSprop(learning_rate=0.000001),loss=keras.losses.BinaryCrossentropy(),metrics=[\"accuracy\"])\n",
    "\n",
    "epochs = 40\n",
    "history = model.fit(dataset_train, epochs=epochs)\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.scatter(epochs_range, acc, label='Training Accuracy')\n",
    "\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.scatter(epochs_range, loss, label='Training Loss')\n",
    "plt.title('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "print(\"val:\")\n",
    "model.evaluate(dataset_val)\n",
    "print(\"test1:\")\n",
    "model.evaluate(dataset_test)\n",
    "# print(\"test2:\")\n",
    "# model.evaluate(dataset_test2)\n",
    "# print(\"test2_crop:\")\n",
    "# model.evaluate(dataset_test2_crop)\n",
    "print(\"\")\n",
    "model.save('ambrosiaTEST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ebb788-6aba-4df8-9704-85fcae5d7f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde2f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optim(parameters, optim_name: str, lr):\n",
    "    optim = {\n",
    "        'SGD': torch.optim.SGD, \n",
    "        'AdamW': torch.optim.AdamW, \n",
    "        'NAdam': torch.optim.NAdam, \n",
    "        'RMSprop': torch.optim.RMSprop, \n",
    "        'Adam': torch.optim.Adam,\n",
    "    }\n",
    "    optimizer = optim(parameters(), lr)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2997267",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m optimizers \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# model = torchvision.models.resnet18\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m optimizer \u001b[39m=\u001b[39m get_optim(model\u001b[39m.\u001b[39;49mparameters(), optimizers, lr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(optimizer)\n",
      "\u001b[1;32m/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_optim\u001b[39m(parameters, optim_name: \u001b[39mstr\u001b[39m, lr):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     optim \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mSGD\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mAdamW\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mAdam\u001b[39m\u001b[39m'\u001b[39m: torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     }\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     optimizer \u001b[39m=\u001b[39m optim(parameters(), lr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m optimizer\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not callable"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(10,1)\n",
    "\n",
    "# params = model.parameters()\n",
    "\n",
    "lr = 0.0001\n",
    "optimizers = 'Adam'\n",
    "\n",
    "# model = torchvision.models.resnet18\n",
    "\n",
    "optimizer = get_optim(model.parameters(), optimizers, lr)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d623f21a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mRMSprop(lr\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m, alpha\u001b[39m=\u001b[39;49m\u001b[39m0.99\u001b[39;49m, eps\u001b[39m=\u001b[39;49m\u001b[39m1e-08\u001b[39;49m, weight_decay\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, momentum\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, centered\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, foreach\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, maximize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, differentiable\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cyber/Desktop/project_AmbrosiaSystem/Learning.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(optimizer)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18\n",
    "optimizer = torch.optim.RMSprop(lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False, foreach=None, maximize=False, differentiable=False)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ce634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
